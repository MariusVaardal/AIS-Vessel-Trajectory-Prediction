{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import timedelta, datetime, timezone\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_to_secs(days):\n",
    "    return days * 24 * 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "timedelta_threshold_days = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_df = pd.read_csv('../datasets/schedules_to_may_2024.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/ais_train.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_df = pd.read_csv('../datasets/schedules_to_may_2024.csv', sep='|')\n",
    "sched_df['arrivalDate'] = pd.to_datetime(sched_df['arrivalDate'])\n",
    "sched_df['sailingDate'] = pd.to_datetime(sched_df['sailingDate'])\n",
    "sched_df = sched_df.sort_values(by=['vesselId', 'arrivalDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_dest_and_time_left(row):\n",
    "    vesselId, timestamp = row['vesselId'], row['time']\n",
    "    timestamp = timestamp.replace(year=timestamp.year - 1)\n",
    "    dest_lon = None\n",
    "    dest_lat = None\n",
    "    time_left = None\n",
    "    for idx, r in sched_df[sched_df['vesselId'] == vesselId].iterrows():\n",
    "        print(f\"r: {r}\")\n",
    "        if timestamp < r['arrivalDate'].replace(tzinfo=None):\n",
    "            dest_lon = r['portLongitude']\n",
    "            dest_lat = r['portLatitude']\n",
    "            time_left = r['arrivalDate'].replace(tzinfo=None) - timestamp\n",
    "            return dest_lon, dest_lat, time_left\n",
    "\n",
    "def should_be_moored(row):\n",
    "    vesselId, timestamp = row['vesselId'], row['time']\n",
    "    for idx, r in sched_df[(sched_df['vesselId'] == vesselId) & (sched_df['arrivalDate'] < timestamp.replace(tzinfo=timezone.utc)) & (sched_df['arrivalDate'] > datetime(2023, 12, 1, 0, 0, tzinfo=timezone.utc))].iterrows():\n",
    "        if timestamp > r['arrivalDate'].replace(tzinfo=None):\n",
    "            if timestamp < r['sailingDate'].replace(tzinfo=None):\n",
    "                return True \n",
    "        else:\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_20308\\3408310297.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_20308\\3408310297.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with too high timedeltas: 0\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\OneDrive\\Desktop\\moderne_maskinlæring\\venv_tdt4173\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mariu\\OneDrive\\Desktop\\moderne_maskinlæring\\venv_tdt4173\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for Latitude: 0.043428654676335415\n",
      "Mean Absolute Error for Longitude: 0.06294103189001747\n"
     ]
    }
   ],
   "source": [
    "filepath_train = '../datasets/ais_train.csv'\n",
    "filepath_test = '../datasets/ais_test.csv'\n",
    "\n",
    "# Load AIS historical data\n",
    "train = pd.read_csv(filepath_train, sep ='|')  # Replace with your dataset\n",
    "test = pd.read_csv(filepath_test, sep = ',')\n",
    "\n",
    "# Preprocessing\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "train.sort_values(by=['vesselId', 'time'], inplace=True)\n",
    "\n",
    "test['time'] = pd.to_datetime(test['time'])\n",
    "test.sort_values(by=['vesselId', 'time'], inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "train['prev_lat'] = train.groupby('vesselId')['latitude'].shift(1)\n",
    "train['prev_lon'] = train.groupby('vesselId')['longitude'].shift(1)\n",
    "train['prev_speed'] = train.groupby('vesselId')['sog'].shift(1)\n",
    "train['prev_course'] = (train.groupby('vesselId')['cog'].shift(1) / 180) - 1        # normalized\n",
    "train['prev_rotation'] = train.groupby('vesselId')['rot'].shift(1) \n",
    "train['prev_heading'] = (train.groupby('vesselId')['heading'].shift(1)/ 180) - 1 \n",
    "train['hour'] = train['time'].dt.hour\n",
    "# Could change this to is_weekend\n",
    "train['day_of_week'] = train['time'].dt.dayofweek\n",
    "# Adding timedelta as a feature\n",
    "train['time_diff'] = train['time'].diff()\n",
    "train['time_diff_seconds'] = train['time_diff'].dt.total_seconds()\n",
    "\n",
    "# # Add schedule related stuff\n",
    "# train['should_be_moored'] = train.apply(should_be_moored, axis=1)\n",
    "# train.to_csv('../datasets/ais_train_preprocessed.csv')\n",
    "\n",
    "# --------------------------------- prev_rot-related stuff\n",
    "# Replace special values with NaN\n",
    "train['prev_rotation'] = train['prev_rotation'].replace({127: np.nan, -127: np.nan, -128: np.nan})\n",
    "# Optional: Create a new column for turn information availability\n",
    "train['turn_info_available'] = np.where(train['prev_rotation'] == -128, 0, 1)\n",
    "\n",
    "# Create binary columns for turn direction and magnitude\n",
    "train['turn_direction'] = np.where(train['prev_rotation'] > 0, 'right', 'left')\n",
    "train['turn_magnitude'] = train['prev_rotation'].abs()\n",
    "\n",
    "# Fill missing values (optional, using forward fill) Uses most recent non-null value from the row above.\n",
    "train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "rows_w_too_large_timedelta_idx = train[train['time_diff_seconds'] > days_to_secs(timedelta_threshold_days)].index.to_list()\n",
    "earliest_idx = train.groupby('vesselId')['time'].idxmin().tolist()\n",
    "idx_to_drop = rows_w_too_large_timedelta_idx + earliest_idx\n",
    "train = train.drop(idx_to_drop).reset_index(drop=True)\n",
    "\n",
    "# REMOVE THIS \n",
    "print(f\"Rows with too high timedeltas: {len(rows_w_too_large_timedelta_idx)}\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "train.dropna(inplace=True)\n",
    "\n",
    "# Define features and target variables\n",
    "X = train[['prev_lat', 'prev_lon', 'prev_speed', 'prev_course','prev_rotation', 'turn_info_available', 'prev_heading', 'time_diff_seconds']]\n",
    "y_lat = train['latitude']\n",
    "y_lon = train['longitude']\n",
    "X_test = test\n",
    "\n",
    "X_lat_train, X_lat_val, y_lat_train, y_lat_val = train_test_split(X, y_lat, test_size=0.1, random_state=42)\n",
    "X_lon_train, X_lon_val, y_lon_train, y_lon_val = train_test_split(X, y_lon, test_size=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_lat = RandomForestRegressor(n_estimators=20, verbose=3, random_state=42)\n",
    "model_lat.fit(X_lat_train.values, y_lat_train.values)\n",
    "\n",
    "model_lon = RandomForestRegressor(n_estimators=20, verbose=3, random_state=42)\n",
    "model_lon.fit(X_lon_train.values, y_lon_train.values)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_lat_pred_val = model_lat.predict(X_lat_val)\n",
    "y_lon_pred_val = model_lon.predict(X_lon_val)\n",
    "\n",
    "# Evaluate performance on the validation set\n",
    "mae_lat = mean_absolute_error(y_lat_val, y_lat_pred_val)\n",
    "mae_lon = mean_absolute_error(y_lon_val, y_lon_pred_val)\n",
    "\n",
    "print(f'Mean Absolute Error for Latitude: {mae_lat}')\n",
    "print(f'Mean Absolute Error for Longitude: {mae_lon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AIS historical data\n",
    "training_data = pd.read_csv(filepath_train, sep ='|')  # Replace with your dataset\n",
    "\n",
    "# Predict future positions\n",
    "def predict_future_position(id, vessel_id, time):\n",
    "    # Fetch the latest known position of the vessel\n",
    "    latest_data = training_data[training_data['vesselId'] == vessel_id].sort_values(by='time').iloc[-1]\n",
    "\n",
    "    new_data = {\n",
    "        'prev_lat': latest_data['latitude'],\n",
    "        'prev_lon': latest_data['longitude'],\n",
    "        'prev_speed': latest_data['sog'],\n",
    "        'prev_course': (latest_data['cog'] / 180) - 1,\n",
    "        'prev_rotation': latest_data['rot'],\n",
    "        'turn_info_available': 1 if latest_data['rot'] != -128 else 0,\n",
    "        'prev_heading' : (latest_data['heading'] / 180) - 1,\n",
    "\n",
    "        # Convert the times to a datetime_obj\n",
    "        'time_diff_seconds' : (datetime.strptime(time, '%Y-%m-%d %H:%M:%S') - datetime.strptime(latest_data['time'], '%Y-%m-%d %H:%M:%S')).total_seconds(),\n",
    "    }\n",
    "    # why is it done with all this list stuff?\n",
    "    return id, model_lat.predict([list(new_data.values())])[0], model_lon.predict([list(new_data.values())])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the test file for reading and the prediction file for writing\n",
    "with open('../datasets/ais_test.csv', 'r') as f_test, open('../predictions/predictions.csv', 'w') as f_pred:\n",
    "    f_pred.write(\"ID,longitude_predicted,latitude_predicted\\n\")\n",
    "    for line in f_test.readlines()[1:]:\n",
    "        id, vesselID, time, scaling_factor = line.split(',')\n",
    "        id, pred_lat, pred_lon = predict_future_position(id, vesselID, time)\n",
    "        f_pred.write(f\"{id},{pred_lon},{pred_lat}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
