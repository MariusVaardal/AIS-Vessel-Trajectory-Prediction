{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import timedelta, datetime, timezone\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_to_secs(days):\n",
    "    return days * 24 * 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "timedelta_threshold_days = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_df = pd.read_csv('../datasets/schedules_to_may_2024.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/ais_train.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_df = pd.read_csv('../datasets/schedules_to_may_2024.csv', sep='|')\n",
    "sched_df['arrivalDate'] = pd.to_datetime(sched_df['arrivalDate'])\n",
    "sched_df['sailingDate'] = pd.to_datetime(sched_df['sailingDate'])\n",
    "sched_df = sched_df.sort_values(by=['vesselId', 'arrivalDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_dest_and_time_left(row):\n",
    "    vesselId, timestamp = row['vesselId'], row['time']\n",
    "    timestamp = timestamp.replace(year=timestamp.year - 1)\n",
    "    dest_lon = None\n",
    "    dest_lat = None\n",
    "    time_left = None\n",
    "    for idx, r in sched_df[sched_df['vesselId'] == vesselId].iterrows():\n",
    "        print(f\"r: {r}\")\n",
    "        if timestamp < r['arrivalDate'].replace(tzinfo=None):\n",
    "            dest_lon = r['portLongitude']\n",
    "            dest_lat = r['portLatitude']\n",
    "            time_left = r['arrivalDate'].replace(tzinfo=None) - timestamp\n",
    "            return dest_lon, dest_lat, time_left\n",
    "\n",
    "def should_be_moored(row):\n",
    "    vesselId, timestamp = row['vesselId'], row['time']\n",
    "    for idx, r in sched_df[(sched_df['vesselId'] == vesselId) & (sched_df['arrivalDate'] < timestamp.replace(tzinfo=timezone.utc)) & (sched_df['arrivalDate'] > datetime(2023, 12, 1, 0, 0, tzinfo=timezone.utc))].iterrows():\n",
    "        if timestamp > r['arrivalDate'].replace(tzinfo=None):\n",
    "            if timestamp < r['sailingDate'].replace(tzinfo=None):\n",
    "                return True \n",
    "        else:\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_20308\\3408310297.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_20308\\3408310297.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with too high timedeltas: 0\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mariu\\OneDrive\\Desktop\\moderne_maskinlæring\\venv_tdt4173\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mariu\\OneDrive\\Desktop\\moderne_maskinlæring\\venv_tdt4173\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for Latitude: 0.043428654676335415\n",
      "Mean Absolute Error for Longitude: 0.06294103189001747\n"
     ]
    }
   ],
   "source": [
    "filepath_train = '../datasets/ais_train.csv'\n",
    "filepath_test = '../datasets/ais_test.csv'\n",
    "\n",
    "# Load AIS historical data\n",
    "train = pd.read_csv(filepath_train, sep ='|')  # Replace with your dataset\n",
    "test = pd.read_csv(filepath_test, sep = ',')\n",
    "\n",
    "# Preprocessing\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "train.sort_values(by=['vesselId', 'time'], inplace=True)\n",
    "\n",
    "test['time'] = pd.to_datetime(test['time'])\n",
    "test.sort_values(by=['vesselId', 'time'], inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "train['prev_lat'] = train.groupby('vesselId')['latitude'].shift(1)\n",
    "train['prev_lon'] = train.groupby('vesselId')['longitude'].shift(1)\n",
    "train['prev_speed'] = train.groupby('vesselId')['sog'].shift(1)\n",
    "train['prev_course'] = (train.groupby('vesselId')['cog'].shift(1) / 180) - 1        # normalized\n",
    "train['prev_rotation'] = train.groupby('vesselId')['rot'].shift(1) \n",
    "train['prev_heading'] = (train.groupby('vesselId')['heading'].shift(1)/ 180) - 1 \n",
    "train['hour'] = train['time'].dt.hour\n",
    "# Could change this to is_weekend\n",
    "train['day_of_week'] = train['time'].dt.dayofweek\n",
    "# Adding timedelta as a feature\n",
    "train['time_diff'] = train['time'].diff()\n",
    "train['time_diff_seconds'] = train['time_diff'].dt.total_seconds()\n",
    "\n",
    "# # Add schedule related stuff\n",
    "# train['should_be_moored'] = train.apply(should_be_moored, axis=1)\n",
    "# train.to_csv('../datasets/ais_train_preprocessed.csv')\n",
    "\n",
    "# --------------------------------- prev_rot-related stuff\n",
    "# Replace special values with NaN\n",
    "train['prev_rotation'] = train['prev_rotation'].replace({127: np.nan, -127: np.nan, -128: np.nan})\n",
    "# Optional: Create a new column for turn information availability\n",
    "train['turn_info_available'] = np.where(train['prev_rotation'] == -128, 0, 1)\n",
    "\n",
    "# Create binary columns for turn direction and magnitude\n",
    "train['turn_direction'] = np.where(train['prev_rotation'] > 0, 'right', 'left')\n",
    "train['turn_magnitude'] = train['prev_rotation'].abs()\n",
    "\n",
    "# Fill missing values (optional, using forward fill) Uses most recent non-null value from the row above.\n",
    "train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "rows_w_too_large_timedelta_idx = train[train['time_diff_seconds'] > days_to_secs(timedelta_threshold_days)].index.to_list()\n",
    "earliest_idx = train.groupby('vesselId')['time'].idxmin().tolist()\n",
    "idx_to_drop = rows_w_too_large_timedelta_idx + earliest_idx\n",
    "train = train.drop(idx_to_drop).reset_index(drop=True)\n",
    "\n",
    "# REMOVE THIS \n",
    "print(f\"Rows with too high timedeltas: {len(rows_w_too_large_timedelta_idx)}\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "train.dropna(inplace=True)\n",
    "\n",
    "# Define features and target variables\n",
    "X = train[['prev_lat', 'prev_lon', 'prev_speed', 'prev_course','prev_rotation', 'turn_info_available', 'prev_heading', 'time_diff_seconds']]\n",
    "y_lat = train['latitude']\n",
    "y_lon = train['longitude']\n",
    "X_test = test\n",
    "\n",
    "X_lat_train, X_lat_val, y_lat_train, y_lat_val = train_test_split(X, y_lat, test_size=0.1, random_state=42)\n",
    "X_lon_train, X_lon_val, y_lon_train, y_lon_val = train_test_split(X, y_lon, test_size=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_lat = RandomForestRegressor(n_estimators=20, verbose=3, random_state=42)\n",
    "model_lat.fit(X_lat_train.values, y_lat_train.values)\n",
    "\n",
    "model_lon = RandomForestRegressor(n_estimators=20, verbose=3, random_state=42)\n",
    "model_lon.fit(X_lon_train.values, y_lon_train.values)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_lat_pred_val = model_lat.predict(X_lat_val)\n",
    "y_lon_pred_val = model_lon.predict(X_lon_val)\n",
    "\n",
    "# Evaluate performance on the validation set\n",
    "mae_lat = mean_absolute_error(y_lat_val, y_lat_pred_val)\n",
    "mae_lon = mean_absolute_error(y_lon_val, y_lon_pred_val)\n",
    "\n",
    "print(f'Mean Absolute Error for Latitude: {mae_lat}')\n",
    "print(f'Mean Absolute Error for Longitude: {mae_lon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AIS historical data\n",
    "training_data = pd.read_csv(filepath_train, sep ='|')  # Replace with your dataset\n",
    "\n",
    "# Predict future positions\n",
    "def predict_future_position(id, vessel_id, time):\n",
    "    # Fetch the latest known position of the vessel\n",
    "    latest_data = training_data[training_data['vesselId'] == vessel_id].sort_values(by='time').iloc[-1]\n",
    "\n",
    "    new_data = {\n",
    "        'prev_lat': latest_data['latitude'],\n",
    "        'prev_lon': latest_data['longitude'],\n",
    "        'prev_speed': latest_data['sog'],\n",
    "        'prev_course': (latest_data['cog'] / 180) - 1,\n",
    "        'prev_rotation': latest_data['rot'],\n",
    "        'turn_info_available': 1 if latest_data['rot'] != -128 else 0,\n",
    "        'prev_heading' : (latest_data['heading'] / 180) - 1,\n",
    "\n",
    "        # Convert the times to a datetime_obj\n",
    "        'time_diff_seconds' : (datetime.strptime(time, '%Y-%m-%d %H:%M:%S') - datetime.strptime(latest_data['time'], '%Y-%m-%d %H:%M:%S')).total_seconds(),\n",
    "    }\n",
    "    # why is it done with all this list stuff?\n",
    "    return id, model_lat.predict([list(new_data.values())])[0], model_lon.predict([list(new_data.values())])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f_test\u001b[38;5;241m.\u001b[39mreadlines()[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mid\u001b[39m, vesselID, time, scaling_factor \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28mid\u001b[39m, pred_lat, pred_lon \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_future_position\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvesselID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     f_pred\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_lon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_lat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m, in \u001b[0;36mpredict_future_position\u001b[1;34m(id, vessel_id, time)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_future_position\u001b[39m(\u001b[38;5;28mid\u001b[39m, vessel_id, time):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Fetch the latest known position of the vessel\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     latest_data \u001b[38;5;241m=\u001b[39m training_data[\u001b[43mtraining_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvesselId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvessel_id\u001b[49m]\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      9\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_lat\u001b[39m\u001b[38;5;124m'\u001b[39m: latest_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_lon\u001b[39m\u001b[38;5;124m'\u001b[39m: latest_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_diff_seconds\u001b[39m\u001b[38;5;124m'\u001b[39m : (datetime\u001b[38;5;241m.\u001b[39mstrptime(time, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(latest_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mtotal_seconds(),\n\u001b[0;32m     20\u001b[0m     }\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# why is it done with all this list stuff?\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mariu\\OneDrive\\Desktop\\moderne_maskinlæring\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mariu\\OneDrive\\Desktop\\moderne_maskinlæring\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mariu\\OneDrive\\Desktop\\moderne_maskinlæring\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\mariu\\OneDrive\\Desktop\\moderne_maskinlæring\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mariu\\OneDrive\\Desktop\\moderne_maskinlæring\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:130\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Open the test file for reading and the prediction file for writing\n",
    "with open('../datasets/ais_test.csv', 'r') as f_test, open('../predictions/predictions.csv', 'w') as f_pred:\n",
    "    f_pred.write(\"ID,longitude_predicted,latitude_predicted\\n\")\n",
    "    for line in f_test.readlines()[1:]:\n",
    "        id, vesselID, time, scaling_factor = line.split(',')\n",
    "        id, pred_lat, pred_lon = predict_future_position(id, vesselID, time)\n",
    "        f_pred.write(f\"{id},{pred_lon},{pred_lat}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
