{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report: AIS Vessel Trajectory Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain knowledge\n",
    "AIS is a short range tracking system that transmits ships positions using the high frequency maritime frequency band. It was originally developed as a collision avoidance tool. Each ship transmits a signal containing vessel identity, position, speed and course to surrounding ships and shore stations. The position of the ship is obtained by either using the ships GPS signal or an inertial sensor built into the AIS unit. Static information is sent every sixth minute or at request the ship sends MMSI number, IMO number, name and call sign, length and beam, type of ship and location of position fixing antenna. Dynamic information is sent dependent on the speed and course alterations of the ship. The dynamic information consist of Ships position, accuracy indication, position timestamp and the course over ground. \n",
    "\n",
    "It is mandatory for all ships above 300 GT (gross tonnage) to carry AIS, and it is illegal to turn it of. All 300 GT boats mus carry a class A AIS system, while other boats like pleasure crafts can carry a class B AIS system with limited functionality. \n",
    "\n",
    "The signals are sensible to noise and enviromental disturbances. Making AIS unpredictable. Some relevant factors are signal propagation conditions, sea state, the height of antennas and strength of the transmitter. These factors giva a large variation in signal transmition length from 20-350 nautical miles. But an average of 40 nautical miles can safely be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data intuitition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heading is given in angular degrees from north from 0 deg to 359 deg. It is also quite noisy and could use filtering first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size) / window_size, mode='same')\n",
    "\n",
    "# Example: Applying a moving average filter\n",
    "window_size = 5  # You can adjust the window size based on the level of smoothing you need\n",
    "\n",
    "def exponential_moving_average(data, alpha):\n",
    "    ema = [data[0]]  # Initialize with the first data point\n",
    "    for i in range(1, len(data)):\n",
    "        ema.append(alpha * data[i] + (1 - alpha) * ema[i - 1])\n",
    "    return np.array(ema)\n",
    "\n",
    "# Example: Applying EMA\n",
    "alpha = 0.3  # Smoothing factor (0 < alpha <= 1)\n",
    "\n",
    "def low_pass_filter(data, cutoff_freq, sampling_rate):\n",
    "    fft_data = np.fft.fft(data)\n",
    "    frequencies = np.fft.fftfreq(len(data), d=1/sampling_rate)\n",
    "    \n",
    "    # Zero out frequencies higher than the cutoff\n",
    "    fft_data[np.abs(frequencies) > cutoff_freq] = 0\n",
    "    \n",
    "    # Inverse FFT to get the filtered signal\n",
    "    return np.fft.ifft(fft_data)\n",
    "\n",
    "# Example: Applying a low-pass filter\n",
    "cutoff_frequency = 0.1  # Define the cutoff frequency\n",
    "sampling_rate = 1  # Define the sampling rate (based on time intervals of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a spread in how many samples there are in each timeslot. The AIS should be periodically and it should have the same number within each timeslot. There is also a big difference in the number of samples between the different ships. There is also huge gaps between each sequence of AIS data. Could split up each ship in continous slots where AIS is available. Seems like it spams AIS data when they are stationary. \n",
    "\n",
    "The cog measurement is really noisy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sched_df = pd.read_csv('../datasets/schedules_to_may_2024.csv', sep='|')\n",
    "sched_df['arrivalDate'] = pd.to_datetime(sched_df['arrivalDate'])\n",
    "sched_df['sailingDate'] = pd.to_datetime(sched_df['sailingDate'])\n",
    "sched_df = sched_df.sort_values(by=['vesselId', 'arrivalDate'])\n",
    "\n",
    "def get_next_dest_and_time_left(row, prev_pos_avail=True):\n",
    "    vesselId, timestamp = row['vesselId'], row['time']\n",
    "    dest_lon = None\n",
    "    dest_lat = None\n",
    "    time_left = None\n",
    "    for idx, r in sched_df[sched_df['vesselId'] == vesselId].iterrows():\n",
    "        if timestamp < r['arrivalDate'].replace(tzinfo=None):\n",
    "            dest_lon = r['portLongitude']\n",
    "            dest_lat = r['portLatitude']\n",
    "            time_left = r['arrivalDate'].replace(tzinfo=None) - timestamp\n",
    "            ret_is_valid = int(not np.isnan(dest_lon) and not np.isnan(dest_lat))\n",
    "            if not ret_is_valid:\n",
    "                if not prev_pos_avail:\n",
    "                    lon = row['longitude']\n",
    "                    lat = row['latitude']\n",
    "                else:\n",
    "                    lon = row['prev_lon']\n",
    "                    lat = row['prev_lat']\n",
    "                return lon, lat, 1, ret_is_valid\n",
    "            return dest_lon, dest_lat, time_left.total_seconds(), ret_is_valid\n",
    "    if not prev_pos_avail:\n",
    "        lon = row['longitude']\n",
    "        lat = row['latitude']\n",
    "    else:\n",
    "        lon = row['prev_lon']\n",
    "        lat = row['prev_lat']\n",
    "    return lon, lat, 1, 0\n",
    "\n",
    "def should_be_moored(row):\n",
    "    vesselId, timestamp = row['vesselId'], row['time']\n",
    "    for idx, r in sched_df[(sched_df['vesselId'] == vesselId) & (sched_df['arrivalDate'] < timestamp.replace(tzinfo=timezone.utc)) & (sched_df['arrivalDate'] > datetime(2023, 12, 1, 0, 0, tzinfo=timezone.utc))].iterrows():\n",
    "        if timestamp > r['arrivalDate'].replace(tzinfo=None):\n",
    "            if timestamp < r['sailingDate'].replace(tzinfo=None):\n",
    "                return 1 \n",
    "        else:\n",
    "            return 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marvaar\\AppData\\Local\\Temp\\ipykernel_15180\\779510814.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\marvaar\\AppData\\Local\\Temp\\ipykernel_15180\\779510814.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprev_rotation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffill\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Apply the function and assign the result to multiple columns\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m train[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdest_lon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdest_lat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_left\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msched_data_available\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_next_dest_and_time_left\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexpand\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Drop rows with missing values\u001b[39;00m\n\u001b[0;32m     50\u001b[0m train\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[36], line 11\u001b[0m, in \u001b[0;36mget_next_dest_and_time_left\u001b[1;34m(row, prev_pos_avail)\u001b[0m\n\u001b[0;32m      9\u001b[0m dest_lat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     10\u001b[0m time_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, r \u001b[38;5;129;01min\u001b[39;00m sched_df[\u001b[43msched_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvesselId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvesselId\u001b[49m]\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timestamp \u001b[38;5;241m<\u001b[39m r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marrivalDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(tzinfo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     13\u001b[0m         dest_lon \u001b[38;5;241m=\u001b[39m r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:130\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filepath_train = '../datasets/ais_train.csv'\n",
    "filepath_test = '../datasets/ais_test.csv'\n",
    "\n",
    "# Load AIS historical data\n",
    "train = pd.read_csv(filepath_train, sep ='|')  # Replace with your dataset\n",
    "test = pd.read_csv(filepath_test, sep = ',')\n",
    "\n",
    "# Preprocessing\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "train.sort_values(by=['vesselId', 'time'], inplace=True)\n",
    "train['isMoored'] = train['navstat']== 5\n",
    "# Why are we using the complement?\n",
    "train = train[~train['isMoored']]\n",
    "\n",
    "test['time'] = pd.to_datetime(test['time'])\n",
    "test.sort_values(by=['vesselId', 'time'], inplace=True)\n",
    "\n",
    "# Feature Engineering\n",
    "train['prev_lat'] = train.groupby('vesselId')['latitude'].shift(1)\n",
    "train['prev_lon'] = train.groupby('vesselId')['longitude'].shift(1)\n",
    "train['prev_speed'] = train.groupby('vesselId')['sog'].shift(1)\n",
    "train['prev_course'] = (train.groupby('vesselId')['cog'].shift(1) / 180) - 1        # normalized\n",
    "train['prev_rotation'] = train.groupby('vesselId')['rot'].shift(1) \n",
    "train['prev_heading'] = (train.groupby('vesselId')['heading'].shift(1)/ 180) - 1 \n",
    "train['hour'] = train['time'].dt.hour\n",
    "# Could change this to is_weekend\n",
    "train['day_of_week'] = train['time'].dt.dayofweek\n",
    "# Adding timedelta as a feature\n",
    "train['time_diff'] = train['time'].diff()\n",
    "train['time_diff_seconds'] = train['time_diff'].dt.total_seconds()\n",
    "\n",
    "\n",
    "# --------------------------------- prev_rot-related stuff\n",
    "# Replace special values with NaN\n",
    "train['prev_rotation'] = train['prev_rotation'].replace({127: np.nan, -127: np.nan, -128: np.nan})\n",
    "# Optional: Create a new column for turn information availability\n",
    "train['turn_info_available'] = np.where(train['prev_rotation'] == -128, 0, 1)\n",
    "\n",
    "# Create binary columns for turn direction and magnitude\n",
    "train['turn_direction'] = np.where(train['prev_rotation'] > 0, 'right', 'left')\n",
    "train['turn_magnitude'] = train['prev_rotation'].abs()\n",
    "\n",
    "# Fill missing values (optional, using forward fill) Uses most recent non-null value from the row above.\n",
    "train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Drop rows with missing values\n",
    "train.dropna(inplace=True)\n",
    "\n",
    "print(f\"Length of dataset after preprocessing: {len(train)}\")\n",
    "\n",
    "# Define features and target variables\n",
    "X = train[['prev_lat', 'prev_lon', 'prev_speed', 'prev_course','prev_rotation', 'turn_info_available', 'prev_heading', 'time_diff_seconds']]\n",
    "y_lat = train['latitude']\n",
    "y_lon = train['longitude']\n",
    "X_test = test\n",
    "\n",
    "X_lat_train, X_lat_val, y_lat_train, y_lat_val = train_test_split(X, y_lat, test_size=0.1, random_state=42)\n",
    "X_lon_train, X_lon_val, y_lon_train, y_lon_val = train_test_split(X, y_lon, test_size=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_lat = RandomForestRegressor(n_estimators=20, verbose=3, random_state=42)\n",
    "model_lat.fit(X_lat_train.values, y_lat_train.values)\n",
    "\n",
    "model_lon = RandomForestRegressor(n_estimators=20, verbose=3, random_state=42)\n",
    "model_lon.fit(X_lon_train.values, y_lon_train.values)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_lat_pred_val = model_lat.predict(X_lat_val)\n",
    "y_lon_pred_val = model_lon.predict(X_lon_val)\n",
    "\n",
    "# Evaluate performance on the validation set\n",
    "mae_lat = mean_absolute_error(y_lat_val, y_lat_pred_val)\n",
    "mae_lon = mean_absolute_error(y_lon_val, y_lon_pred_val)\n",
    "\n",
    "print(f'Mean Absolute Error for Latitude: {mae_lat}')\n",
    "print(f'Mean Absolute Error for Longitude: {mae_lon}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'time', 'cog', 'sog', 'rot', 'heading', 'navstat',\n",
      "       'etaRaw', 'latitude', 'longitude', 'vesselId', 'portId', 'prev_lat',\n",
      "       'prev_lon', 'prev_speed', 'prev_course', 'prev_rotation',\n",
      "       'prev_heading', 'hour', 'day_of_week', 'time_diff', 'time_diff_seconds',\n",
      "       'turn_info_available', 'turn_direction', 'turn_magnitude',\n",
      "       'should_be_moored', 'dest_lon', 'dest_lat', 'time_left',\n",
      "       'sched_data_available'],\n",
      "      dtype='object')\n",
      "Length of training dataset: 894129\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n",
      "building tree 1 of 20\n",
      "building tree 2 of 20\n",
      "building tree 3 of 20\n",
      "building tree 4 of 20\n",
      "building tree 5 of 20\n",
      "building tree 6 of 20\n",
      "building tree 7 of 20\n",
      "building tree 8 of 20\n",
      "building tree 9 of 20\n",
      "building tree 10 of 20\n",
      "building tree 11 of 20\n",
      "building tree 12 of 20\n",
      "building tree 13 of 20\n",
      "building tree 14 of 20\n",
      "building tree 15 of 20\n",
      "building tree 16 of 20\n",
      "building tree 17 of 20\n",
      "building tree 18 of 20\n",
      "building tree 19 of 20\n",
      "building tree 20 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\marvaar\\Documents\\tdt4173\\venv_tdt4173\\Lib\\site-packages\\sklearn\\base.py:486: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for Latitude: 0.07214914520212934\n",
      "Mean Absolute Error for Longitude: 0.11517558508570855\n"
     ]
    }
   ],
   "source": [
    "filepath_train = '../datasets/ais_train_preprocessed.csv'\n",
    "filepath_test = '../datasets/ais_test.csv'\n",
    "\n",
    "# Load AIS historical data\n",
    "train = pd.read_csv(filepath_train, sep =',')  # Replace with your dataset\n",
    "\n",
    "# Preprocessing\n",
    "print(train.columns)\n",
    "train['time'] = pd.to_datetime(train['time'])\n",
    "train.sort_values(by=['vesselId', 'time'], inplace=True)\n",
    "train['isMoored'] = train['navstat']== 5\n",
    "# Why are we using the complement?\n",
    "train = train[~train['isMoored']]\n",
    "\n",
    "print(f\"Length of training dataset: {len(train)}\")\n",
    "\n",
    "# Define features and target variables\n",
    "X = train[['prev_lat', 'prev_lon', 'prev_speed', 'prev_course','prev_rotation', 'turn_info_available', 'prev_heading', 'time_diff_seconds', 'should_be_moored', 'dest_lon', 'dest_lat', 'time_left', 'sched_data_available', 'day_of_week']]\n",
    "y_lat = train['latitude']\n",
    "y_lon = train['longitude']\n",
    "\n",
    "X_lat_train, X_lat_val, y_lat_train, y_lat_val = train_test_split(X, y_lat, test_size=0.1, random_state=42)\n",
    "X_lon_train, X_lon_val, y_lon_train, y_lon_val = train_test_split(X, y_lon, test_size=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_lat = RandomForestRegressor(n_estimators=20, verbose=3, random_state=42)\n",
    "model_lat.fit(X_lat_train.values, y_lat_train.values)\n",
    "\n",
    "model_lon = RandomForestRegressor(n_estimators=20, verbose=3, random_state=42)\n",
    "model_lon.fit(X_lon_train.values, y_lon_train.values)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_lat_pred_val = model_lat.predict(X_lat_val)\n",
    "y_lon_pred_val = model_lon.predict(X_lon_val)\n",
    "\n",
    "# Evaluate performance on the validation set\n",
    "mae_lat = mean_absolute_error(y_lat_val, y_lat_pred_val)\n",
    "mae_lon = mean_absolute_error(y_lon_val, y_lon_pred_val)\n",
    "\n",
    "print(f'Mean Absolute Error for Latitude: {mae_lat}')\n",
    "print(f'Mean Absolute Error for Longitude: {mae_lon}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_set(n_shifts):\n",
    "    filepath_train = '../datasets/ais_train.csv'\n",
    "    filepath_test = '../datasets/ais_test.csv'\n",
    "\n",
    "    # Load AIS historical data\n",
    "    train = pd.read_csv(filepath_train, sep ='|')  # Replace with your dataset\n",
    "    test = pd.read_csv(filepath_test, sep = ',')\n",
    "\n",
    "    # Preprocessing\n",
    "    train['time'] = pd.to_datetime(train['time'])\n",
    "    train.sort_values(by=['vesselId', 'time'], inplace=True)\n",
    "    train['isMoored'] = train['navstat']== 5\n",
    "    # Why are we using the complement?\n",
    "    train = train[~train['isMoored']]\n",
    "\n",
    "    test['time'] = pd.to_datetime(test['time'])\n",
    "    test.sort_values(by=['vesselId', 'time'], inplace=True)\n",
    "\n",
    "    # Feature Engineering\n",
    "    train['prev_lat'] = train.groupby('vesselId')['latitude'].shift(n_shifts)\n",
    "    train['prev_lon'] = train.groupby('vesselId')['longitude'].shift(n_shifts)\n",
    "    train['prev_speed'] = train.groupby('vesselId')['sog'].shift(n_shifts)\n",
    "    train['prev_course'] = (train.groupby('vesselId')['cog'].shift(n_shifts) / 180) - 1        # normalized\n",
    "    train['prev_rotation'] = train.groupby('vesselId')['rot'].shift(n_shifts) \n",
    "    train['prev_heading'] = (train.groupby('vesselId')['heading'].shift(n_shifts)/ 180) - 1 \n",
    "    train['hour'] = train['time'].dt.hour\n",
    "    # Could change this to is_weekend\n",
    "    train['day_of_week'] = train['time'].dt.dayofweek\n",
    "    # Adding timedelta as a feature\n",
    "    train['time_diff'] = train['time'].diff(n_shifts)\n",
    "    train['time_diff_seconds'] = train['time_diff'].dt.total_seconds()\n",
    "\n",
    "    # --------------------------------- prev_rot-related stuff\n",
    "    # Replace special values with NaN\n",
    "    train['prev_rotation'] = train['prev_rotation'].replace({127: np.nan, -127: np.nan, -128: np.nan})\n",
    "    # Optional: Create a new column for turn information availability\n",
    "    train['turn_info_available'] = np.where(train['prev_rotation'] == -128, 0, 1)\n",
    "\n",
    "    # Create binary columns for turn direction and magnitude\n",
    "    train['turn_direction'] = np.where(train['prev_rotation'] > 0, 'right', 'left')\n",
    "    train['turn_magnitude'] = train['prev_rotation'].abs()\n",
    "\n",
    "    # Fill missing values (optional, using forward fill) Uses most recent non-null value from the row above.\n",
    "    train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Drop rows with missing values\n",
    "    train.dropna(inplace=True)\n",
    "\n",
    "    print(f\"Length of dataset after preprocessing: {len(train)}\")\n",
    "    return train\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset after preprocessing: 893318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset after preprocessing: 892648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset after preprocessing: 891977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset after preprocessing: 891308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset after preprocessing: 890631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset after preprocessing: 889969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\mariu\\AppData\\Local\\Temp\\ipykernel_18720\\2864780723.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['prev_rotation'].fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset after preprocessing: 889298\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train1 = make_training_set(1)\n",
    "train2 = make_training_set(2)\n",
    "train3 = make_training_set(3)\n",
    "train4 = make_training_set(4)\n",
    "train5 = make_training_set(5)\n",
    "train6 = make_training_set(6)\n",
    "train7 = make_training_set(7)\n",
    "\n",
    "train = pd.concat([train1, train2, train3, train4, train5, train6, train7], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(30311.52442312245)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['time_diff_seconds'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n"
     ]
    }
   ],
   "source": [
    "feats_to_include = ['prev_lat', 'prev_lon', 'prev_speed', 'prev_course','prev_rotation', 'turn_info_available', 'prev_heading', 'time_diff_seconds']\n",
    "X = train[feats_to_include]\n",
    "y_lat = train['latitude']\n",
    "y_lon = train['longitude']\n",
    "\n",
    "X_lat_train, X_lat_val, y_lat_train, y_lat_val = train_test_split(X, y_lat, test_size=0.1, random_state=42)\n",
    "X_lon_train, X_lon_val, y_lon_train, y_lon_val = train_test_split(X, y_lon, test_size=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_lat = RandomForestRegressor(n_estimators=10, verbose=3, random_state=42)\n",
    "model_lat.fit(X_lat_train.values, y_lat_train.values)\n",
    "\n",
    "model_lon = RandomForestRegressor(n_estimators=10, verbose=3, random_state=42)\n",
    "model_lon.fit(X_lon_train.values, y_lon_train.values)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_lat_pred_val = model_lat.predict(X_lat_val)\n",
    "y_lon_pred_val = model_lon.predict(X_lon_val)\n",
    "\n",
    "# Evaluate performance on the validation set\n",
    "mae_lat = mean_absolute_error(y_lat_val, y_lat_pred_val)\n",
    "mae_lon = mean_absolute_error(y_lon_val, y_lon_pred_val)\n",
    "\n",
    "print(f'Mean Absolute Error for Latitude: {mae_lat}')\n",
    "print(f'Mean Absolute Error for Longitude: {mae_lon}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "filepath_train = '../datasets/ais_train.csv'\n",
    "\n",
    "# Load AIS historical data\n",
    "training_data = pd.read_csv(filepath_train, sep ='|')  # Replace with your dataset\n",
    "\n",
    "# Predict future positions\n",
    "def predict_future_position(id, vessel_id, time):\n",
    "    # Fetch the latest known position of the vessel\n",
    "    latest_data = training_data[training_data['vesselId'] == vessel_id].sort_values(by='time').iloc[-1]\n",
    "\n",
    "    new_data = {\n",
    "        'prev_lat': latest_data['latitude'],\n",
    "        'prev_lon': latest_data['longitude'],\n",
    "        'prev_speed': latest_data['sog'],\n",
    "        'prev_course': (latest_data['cog'] / 180) - 1,\n",
    "        'prev_rotation': latest_data['rot'],\n",
    "        'turn_info_available': 1 if latest_data['rot'] != -128 else 0,\n",
    "        'prev_heading' : (latest_data['heading'] / 180) - 1,\n",
    "\n",
    "        # Convert the times to a datetime_obj\n",
    "        'time_diff_seconds' : (datetime.strptime(time, '%Y-%m-%d %H:%M:%S') - datetime.strptime(latest_data['time'], '%Y-%m-%d %H:%M:%S')).total_seconds(),\n",
    "    }\n",
    "    # why is it done with all this list stuff?\n",
    "    return id, model_lat.predict([list(new_data.values())])[0], model_lon.predict([list(new_data.values())])[0]\n",
    "    # return id, model_lat.predict([list(new_data.values())]), model_lon.predict([list(new_data.values())]), new_data['time_diff_seconds'], latest_data['time']\n",
    "\n",
    "# ['prev_lat', 'prev_lon', 'prev_speed', 'prev_course','prev_rotation', 'turn_info_available', 'prev_heading', 'time_diff_seconds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Open the test file for reading and the prediction file for writing\n",
    "with open('../datasets/ais_test.csv', 'r') as f_test, open('../predictions/predictions_2.csv', 'w') as f_pred:\n",
    "    f_pred.write(\"ID,longitude_predicted,latitude_predicted\\n\")\n",
    "    for line in f_test.readlines()[1:]:\n",
    "        id, vesselID, time, scaling_factor = line.split(',')\n",
    "        id, pred_lat, pred_lon = predict_future_position(id, vesselID, time)\n",
    "        f_pred.write(f\"{id},{pred_lon},{pred_lat}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
